{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Comment', 'Sentiment'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset from CSV file\n",
    "df = pd.read_csv('train_data.csv')\n",
    "\n",
    "# Check the columns\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Comment  Sentiment\n",
      "0  Lets not forget that Apple Pay in 2014 require...          1\n",
      "1  Here in NZ 50 of retailers dont even have cont...          0\n",
      "2  I will forever acknowledge this channel with t...          2\n",
      "3  Whenever I go to a place that doesnt take Appl...          0\n",
      "4  Apple Pay is so convenient secure and easy to ...          2\n"
     ]
    }
   ],
   "source": [
    "# Select only the 'Comment' and 'Sentiment' columns\n",
    "df = df[['Comment', 'Sentiment']]\n",
    "\n",
    "# Check the first few rows of the dataframe\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fdbcac4eb234af6af32865a0b12a495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5505 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9766, 'grad_norm': 4.844658374786377, 'learning_rate': 4.990917347865577e-05, 'epoch': 0.01}\n",
      "{'loss': 0.7371, 'grad_norm': 7.717729091644287, 'learning_rate': 4.981834695731154e-05, 'epoch': 0.01}\n",
      "{'loss': 0.8395, 'grad_norm': 6.978791236877441, 'learning_rate': 4.9727520435967305e-05, 'epoch': 0.02}\n",
      "{'loss': 0.8592, 'grad_norm': 24.968318939208984, 'learning_rate': 4.963669391462307e-05, 'epoch': 0.02}\n",
      "{'loss': 0.699, 'grad_norm': 8.126932144165039, 'learning_rate': 4.954586739327884e-05, 'epoch': 0.03}\n",
      "{'loss': 0.7347, 'grad_norm': 18.910205841064453, 'learning_rate': 4.945504087193461e-05, 'epoch': 0.03}\n",
      "{'loss': 0.8477, 'grad_norm': 8.022194862365723, 'learning_rate': 4.9364214350590375e-05, 'epoch': 0.04}\n",
      "{'loss': 0.47, 'grad_norm': 15.116703987121582, 'learning_rate': 4.927338782924614e-05, 'epoch': 0.04}\n",
      "{'loss': 0.6732, 'grad_norm': 5.749303340911865, 'learning_rate': 4.918256130790191e-05, 'epoch': 0.05}\n",
      "{'loss': 0.5101, 'grad_norm': 6.7499918937683105, 'learning_rate': 4.909173478655768e-05, 'epoch': 0.05}\n",
      "{'loss': 0.7777, 'grad_norm': 3.5522525310516357, 'learning_rate': 4.9000908265213445e-05, 'epoch': 0.06}\n",
      "{'loss': 0.5135, 'grad_norm': 2.236025333404541, 'learning_rate': 4.891008174386921e-05, 'epoch': 0.07}\n",
      "{'loss': 0.4861, 'grad_norm': 8.865370750427246, 'learning_rate': 4.881925522252498e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6426, 'grad_norm': 7.853234767913818, 'learning_rate': 4.872842870118075e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6626, 'grad_norm': 6.213752269744873, 'learning_rate': 4.8637602179836515e-05, 'epoch': 0.08}\n",
      "{'loss': 0.5489, 'grad_norm': 5.393289566040039, 'learning_rate': 4.854677565849228e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6654, 'grad_norm': 5.191370010375977, 'learning_rate': 4.845594913714805e-05, 'epoch': 0.09}\n",
      "{'loss': 0.4022, 'grad_norm': 38.53725814819336, 'learning_rate': 4.836512261580382e-05, 'epoch': 0.1}\n",
      "{'loss': 0.7547, 'grad_norm': 7.412519454956055, 'learning_rate': 4.8274296094459585e-05, 'epoch': 0.1}\n",
      "{'loss': 0.4682, 'grad_norm': 7.713065147399902, 'learning_rate': 4.818346957311535e-05, 'epoch': 0.11}\n",
      "{'loss': 0.5304, 'grad_norm': 12.227036476135254, 'learning_rate': 4.809264305177112e-05, 'epoch': 0.11}\n",
      "{'loss': 0.5911, 'grad_norm': 13.56563663482666, 'learning_rate': 4.800181653042689e-05, 'epoch': 0.12}\n",
      "{'loss': 0.5075, 'grad_norm': 11.95439624786377, 'learning_rate': 4.7910990009082655e-05, 'epoch': 0.13}\n",
      "{'loss': 0.2905, 'grad_norm': 4.379140377044678, 'learning_rate': 4.782016348773842e-05, 'epoch': 0.13}\n",
      "{'loss': 0.5274, 'grad_norm': 13.636223793029785, 'learning_rate': 4.772933696639419e-05, 'epoch': 0.14}\n",
      "{'loss': 0.756, 'grad_norm': 37.01399612426758, 'learning_rate': 4.763851044504996e-05, 'epoch': 0.14}\n",
      "{'loss': 0.427, 'grad_norm': 9.350907325744629, 'learning_rate': 4.7547683923705725e-05, 'epoch': 0.15}\n",
      "{'loss': 0.5541, 'grad_norm': 12.4295015335083, 'learning_rate': 4.745685740236149e-05, 'epoch': 0.15}\n",
      "{'loss': 0.4851, 'grad_norm': 4.0185322761535645, 'learning_rate': 4.736603088101726e-05, 'epoch': 0.16}\n",
      "{'loss': 0.6533, 'grad_norm': 2.434372663497925, 'learning_rate': 4.727520435967303e-05, 'epoch': 0.16}\n",
      "{'loss': 0.554, 'grad_norm': 38.711978912353516, 'learning_rate': 4.7184377838328795e-05, 'epoch': 0.17}\n",
      "{'loss': 0.6679, 'grad_norm': 9.194594383239746, 'learning_rate': 4.709355131698456e-05, 'epoch': 0.17}\n",
      "{'loss': 0.5006, 'grad_norm': 10.715959548950195, 'learning_rate': 4.700272479564033e-05, 'epoch': 0.18}\n",
      "{'loss': 0.7378, 'grad_norm': 2.418611764907837, 'learning_rate': 4.69118982742961e-05, 'epoch': 0.19}\n",
      "{'loss': 0.4057, 'grad_norm': 5.17902135848999, 'learning_rate': 4.6821071752951865e-05, 'epoch': 0.19}\n",
      "{'loss': 0.5254, 'grad_norm': 23.686742782592773, 'learning_rate': 4.673024523160763e-05, 'epoch': 0.2}\n",
      "{'loss': 0.3919, 'grad_norm': 17.828645706176758, 'learning_rate': 4.66394187102634e-05, 'epoch': 0.2}\n",
      "{'loss': 0.4624, 'grad_norm': 17.087175369262695, 'learning_rate': 4.654859218891917e-05, 'epoch': 0.21}\n",
      "{'loss': 0.6032, 'grad_norm': 22.894195556640625, 'learning_rate': 4.6457765667574935e-05, 'epoch': 0.21}\n",
      "{'loss': 0.7115, 'grad_norm': 13.845017433166504, 'learning_rate': 4.63669391462307e-05, 'epoch': 0.22}\n",
      "{'loss': 0.7716, 'grad_norm': 8.64915943145752, 'learning_rate': 4.627611262488647e-05, 'epoch': 0.22}\n",
      "{'loss': 0.4898, 'grad_norm': 7.322962284088135, 'learning_rate': 4.618528610354224e-05, 'epoch': 0.23}\n",
      "{'loss': 0.5336, 'grad_norm': 10.92289924621582, 'learning_rate': 4.6094459582198005e-05, 'epoch': 0.23}\n",
      "{'loss': 0.4869, 'grad_norm': 6.186641693115234, 'learning_rate': 4.600363306085377e-05, 'epoch': 0.24}\n",
      "{'loss': 0.5429, 'grad_norm': 15.078124046325684, 'learning_rate': 4.591280653950954e-05, 'epoch': 0.25}\n",
      "{'loss': 0.6257, 'grad_norm': 13.877922058105469, 'learning_rate': 4.582198001816531e-05, 'epoch': 0.25}\n",
      "{'loss': 0.3284, 'grad_norm': 8.561053276062012, 'learning_rate': 4.5731153496821075e-05, 'epoch': 0.26}\n",
      "{'loss': 0.6462, 'grad_norm': 10.29899787902832, 'learning_rate': 4.564032697547684e-05, 'epoch': 0.26}\n",
      "{'loss': 0.5051, 'grad_norm': 2.862423896789551, 'learning_rate': 4.554950045413261e-05, 'epoch': 0.27}\n",
      "{'loss': 0.4922, 'grad_norm': 11.362486839294434, 'learning_rate': 4.545867393278838e-05, 'epoch': 0.27}\n",
      "{'loss': 0.4443, 'grad_norm': 3.4630179405212402, 'learning_rate': 4.5367847411444145e-05, 'epoch': 0.28}\n",
      "{'loss': 0.5386, 'grad_norm': 10.083183288574219, 'learning_rate': 4.527702089009991e-05, 'epoch': 0.28}\n",
      "{'loss': 0.6072, 'grad_norm': 9.675054550170898, 'learning_rate': 4.518619436875568e-05, 'epoch': 0.29}\n",
      "{'loss': 0.4153, 'grad_norm': 6.772505283355713, 'learning_rate': 4.509536784741145e-05, 'epoch': 0.29}\n",
      "{'loss': 0.468, 'grad_norm': 26.12606430053711, 'learning_rate': 4.5004541326067215e-05, 'epoch': 0.3}\n",
      "{'loss': 0.5674, 'grad_norm': 12.91419506072998, 'learning_rate': 4.491371480472298e-05, 'epoch': 0.31}\n",
      "{'loss': 0.3946, 'grad_norm': 3.862018585205078, 'learning_rate': 4.482288828337875e-05, 'epoch': 0.31}\n",
      "{'loss': 0.6603, 'grad_norm': 15.582418441772461, 'learning_rate': 4.473206176203452e-05, 'epoch': 0.32}\n",
      "{'loss': 0.5644, 'grad_norm': 14.770224571228027, 'learning_rate': 4.4641235240690285e-05, 'epoch': 0.32}\n",
      "{'loss': 0.5523, 'grad_norm': 12.783288955688477, 'learning_rate': 4.4550408719346046e-05, 'epoch': 0.33}\n",
      "{'loss': 0.7239, 'grad_norm': 43.124359130859375, 'learning_rate': 4.445958219800182e-05, 'epoch': 0.33}\n",
      "{'loss': 0.3515, 'grad_norm': 25.031238555908203, 'learning_rate': 4.436875567665759e-05, 'epoch': 0.34}\n",
      "{'loss': 0.6125, 'grad_norm': 18.460887908935547, 'learning_rate': 4.4277929155313355e-05, 'epoch': 0.34}\n",
      "{'loss': 0.5459, 'grad_norm': 10.674943923950195, 'learning_rate': 4.4187102633969116e-05, 'epoch': 0.35}\n",
      "{'loss': 0.4939, 'grad_norm': 9.27149772644043, 'learning_rate': 4.409627611262489e-05, 'epoch': 0.35}\n",
      "{'loss': 0.5265, 'grad_norm': 13.36852741241455, 'learning_rate': 4.400544959128066e-05, 'epoch': 0.36}\n",
      "{'loss': 0.3758, 'grad_norm': 14.04824161529541, 'learning_rate': 4.3914623069936425e-05, 'epoch': 0.37}\n",
      "{'loss': 0.2731, 'grad_norm': 13.778135299682617, 'learning_rate': 4.3823796548592185e-05, 'epoch': 0.37}\n",
      "{'loss': 0.7114, 'grad_norm': 12.918477058410645, 'learning_rate': 4.373297002724796e-05, 'epoch': 0.38}\n",
      "{'loss': 0.5253, 'grad_norm': 13.593833923339844, 'learning_rate': 4.364214350590373e-05, 'epoch': 0.38}\n",
      "{'loss': 0.4963, 'grad_norm': 18.464468002319336, 'learning_rate': 4.3551316984559495e-05, 'epoch': 0.39}\n",
      "{'loss': 0.4903, 'grad_norm': 23.387434005737305, 'learning_rate': 4.3460490463215255e-05, 'epoch': 0.39}\n",
      "{'loss': 0.5134, 'grad_norm': 30.905065536499023, 'learning_rate': 4.336966394187103e-05, 'epoch': 0.4}\n",
      "{'loss': 0.42, 'grad_norm': 11.623497009277344, 'learning_rate': 4.32788374205268e-05, 'epoch': 0.4}\n",
      "{'loss': 0.4092, 'grad_norm': 12.996635437011719, 'learning_rate': 4.3188010899182565e-05, 'epoch': 0.41}\n",
      "{'loss': 0.5196, 'grad_norm': 3.338984966278076, 'learning_rate': 4.3097184377838325e-05, 'epoch': 0.41}\n",
      "{'loss': 0.5775, 'grad_norm': 44.304664611816406, 'learning_rate': 4.30063578564941e-05, 'epoch': 0.42}\n",
      "{'loss': 0.4779, 'grad_norm': 12.984591484069824, 'learning_rate': 4.291553133514987e-05, 'epoch': 0.43}\n",
      "{'loss': 0.3634, 'grad_norm': 17.621559143066406, 'learning_rate': 4.2824704813805635e-05, 'epoch': 0.43}\n",
      "{'loss': 0.5514, 'grad_norm': 6.4538044929504395, 'learning_rate': 4.27338782924614e-05, 'epoch': 0.44}\n",
      "{'loss': 0.4539, 'grad_norm': 2.813354969024658, 'learning_rate': 4.264305177111717e-05, 'epoch': 0.44}\n",
      "{'loss': 0.599, 'grad_norm': 7.67440938949585, 'learning_rate': 4.255222524977294e-05, 'epoch': 0.45}\n",
      "{'loss': 0.6323, 'grad_norm': 11.381529808044434, 'learning_rate': 4.2461398728428705e-05, 'epoch': 0.45}\n",
      "{'loss': 0.4236, 'grad_norm': 11.394940376281738, 'learning_rate': 4.237057220708447e-05, 'epoch': 0.46}\n",
      "{'loss': 0.5051, 'grad_norm': 18.414546966552734, 'learning_rate': 4.227974568574024e-05, 'epoch': 0.46}\n",
      "{'loss': 0.4952, 'grad_norm': 14.159836769104004, 'learning_rate': 4.218891916439601e-05, 'epoch': 0.47}\n",
      "{'loss': 0.7328, 'grad_norm': 23.200937271118164, 'learning_rate': 4.2098092643051775e-05, 'epoch': 0.47}\n",
      "{'loss': 0.4218, 'grad_norm': 25.195510864257812, 'learning_rate': 4.200726612170754e-05, 'epoch': 0.48}\n",
      "{'loss': 0.4691, 'grad_norm': 14.69774055480957, 'learning_rate': 4.191643960036331e-05, 'epoch': 0.49}\n",
      "{'loss': 0.6672, 'grad_norm': 10.02541446685791, 'learning_rate': 4.182561307901908e-05, 'epoch': 0.49}\n",
      "{'loss': 0.5034, 'grad_norm': 11.676477432250977, 'learning_rate': 4.1734786557674845e-05, 'epoch': 0.5}\n",
      "{'loss': 0.3039, 'grad_norm': 11.26783275604248, 'learning_rate': 4.164396003633061e-05, 'epoch': 0.5}\n",
      "{'loss': 0.4457, 'grad_norm': 4.235213279724121, 'learning_rate': 4.155313351498637e-05, 'epoch': 0.51}\n",
      "{'loss': 0.5652, 'grad_norm': 6.410650253295898, 'learning_rate': 4.146230699364215e-05, 'epoch': 0.51}\n",
      "{'loss': 0.6289, 'grad_norm': 14.788553237915039, 'learning_rate': 4.1371480472297915e-05, 'epoch': 0.52}\n",
      "{'loss': 0.4162, 'grad_norm': 19.05508804321289, 'learning_rate': 4.128065395095368e-05, 'epoch': 0.52}\n",
      "{'loss': 0.5663, 'grad_norm': 14.637263298034668, 'learning_rate': 4.118982742960944e-05, 'epoch': 0.53}\n",
      "{'loss': 0.3108, 'grad_norm': 2.9272499084472656, 'learning_rate': 4.109900090826522e-05, 'epoch': 0.53}\n",
      "{'loss': 0.4849, 'grad_norm': 1.1948599815368652, 'learning_rate': 4.1008174386920985e-05, 'epoch': 0.54}\n",
      "{'loss': 0.427, 'grad_norm': 14.338104248046875, 'learning_rate': 4.091734786557675e-05, 'epoch': 0.54}\n",
      "{'loss': 0.5011, 'grad_norm': 4.943966388702393, 'learning_rate': 4.082652134423251e-05, 'epoch': 0.55}\n",
      "{'loss': 0.3594, 'grad_norm': 9.296462059020996, 'learning_rate': 4.073569482288829e-05, 'epoch': 0.56}\n",
      "{'loss': 0.5809, 'grad_norm': 14.565077781677246, 'learning_rate': 4.0644868301544055e-05, 'epoch': 0.56}\n",
      "{'loss': 0.5428, 'grad_norm': 20.840927124023438, 'learning_rate': 4.055404178019982e-05, 'epoch': 0.57}\n",
      "{'loss': 0.3898, 'grad_norm': 4.745372295379639, 'learning_rate': 4.046321525885558e-05, 'epoch': 0.57}\n",
      "{'loss': 0.5197, 'grad_norm': 4.7650957107543945, 'learning_rate': 4.037238873751136e-05, 'epoch': 0.58}\n",
      "{'loss': 0.4973, 'grad_norm': 9.53560733795166, 'learning_rate': 4.0281562216167125e-05, 'epoch': 0.58}\n",
      "{'loss': 0.4543, 'grad_norm': 8.250804901123047, 'learning_rate': 4.019073569482289e-05, 'epoch': 0.59}\n",
      "{'loss': 0.5104, 'grad_norm': 7.315640449523926, 'learning_rate': 4.009990917347865e-05, 'epoch': 0.59}\n",
      "{'loss': 0.4017, 'grad_norm': 48.041873931884766, 'learning_rate': 4.000908265213443e-05, 'epoch': 0.6}\n",
      "{'loss': 0.5283, 'grad_norm': 9.715055465698242, 'learning_rate': 3.9918256130790195e-05, 'epoch': 0.6}\n",
      "{'loss': 0.4051, 'grad_norm': 16.466463088989258, 'learning_rate': 3.982742960944596e-05, 'epoch': 0.61}\n",
      "{'loss': 0.4663, 'grad_norm': 12.813582420349121, 'learning_rate': 3.973660308810172e-05, 'epoch': 0.62}\n",
      "{'loss': 0.5258, 'grad_norm': 3.5961287021636963, 'learning_rate': 3.96457765667575e-05, 'epoch': 0.62}\n",
      "{'loss': 0.5355, 'grad_norm': 13.526009559631348, 'learning_rate': 3.9554950045413265e-05, 'epoch': 0.63}\n",
      "{'loss': 0.4856, 'grad_norm': 15.55926513671875, 'learning_rate': 3.946412352406903e-05, 'epoch': 0.63}\n",
      "{'loss': 0.3657, 'grad_norm': 3.440324306488037, 'learning_rate': 3.937329700272479e-05, 'epoch': 0.64}\n",
      "{'loss': 0.5401, 'grad_norm': 22.121389389038086, 'learning_rate': 3.928247048138057e-05, 'epoch': 0.64}\n",
      "{'loss': 0.3906, 'grad_norm': 12.617485046386719, 'learning_rate': 3.9191643960036335e-05, 'epoch': 0.65}\n",
      "{'loss': 0.4667, 'grad_norm': 13.896615028381348, 'learning_rate': 3.91008174386921e-05, 'epoch': 0.65}\n",
      "{'loss': 0.4307, 'grad_norm': 19.564104080200195, 'learning_rate': 3.900999091734786e-05, 'epoch': 0.66}\n",
      "{'loss': 0.5749, 'grad_norm': 25.281211853027344, 'learning_rate': 3.891916439600363e-05, 'epoch': 0.66}\n",
      "{'loss': 0.4587, 'grad_norm': 3.829113006591797, 'learning_rate': 3.8828337874659405e-05, 'epoch': 0.67}\n",
      "{'loss': 0.3497, 'grad_norm': 12.656139373779297, 'learning_rate': 3.873751135331517e-05, 'epoch': 0.68}\n",
      "{'loss': 0.5038, 'grad_norm': 18.527606964111328, 'learning_rate': 3.864668483197093e-05, 'epoch': 0.68}\n",
      "{'loss': 0.4107, 'grad_norm': 5.047364234924316, 'learning_rate': 3.85558583106267e-05, 'epoch': 0.69}\n",
      "{'loss': 0.5558, 'grad_norm': 18.010456085205078, 'learning_rate': 3.8465031789282475e-05, 'epoch': 0.69}\n",
      "{'loss': 0.4777, 'grad_norm': 11.14574146270752, 'learning_rate': 3.837420526793824e-05, 'epoch': 0.7}\n",
      "{'loss': 0.294, 'grad_norm': 6.284323692321777, 'learning_rate': 3.828337874659401e-05, 'epoch': 0.7}\n",
      "{'loss': 0.5372, 'grad_norm': 12.297983169555664, 'learning_rate': 3.819255222524977e-05, 'epoch': 0.71}\n",
      "{'loss': 0.3245, 'grad_norm': 4.599438190460205, 'learning_rate': 3.8101725703905545e-05, 'epoch': 0.71}\n",
      "{'loss': 0.3749, 'grad_norm': 3.614203929901123, 'learning_rate': 3.801089918256131e-05, 'epoch': 0.72}\n",
      "{'loss': 0.5218, 'grad_norm': 12.567663192749023, 'learning_rate': 3.792007266121708e-05, 'epoch': 0.72}\n",
      "{'loss': 0.4, 'grad_norm': 22.58513832092285, 'learning_rate': 3.782924613987284e-05, 'epoch': 0.73}\n",
      "{'loss': 0.4049, 'grad_norm': 19.545772552490234, 'learning_rate': 3.7738419618528615e-05, 'epoch': 0.74}\n",
      "{'loss': 0.5495, 'grad_norm': 23.752927780151367, 'learning_rate': 3.764759309718438e-05, 'epoch': 0.74}\n",
      "{'loss': 0.5343, 'grad_norm': 22.613195419311523, 'learning_rate': 3.755676657584015e-05, 'epoch': 0.75}\n",
      "{'loss': 0.5038, 'grad_norm': 10.275788307189941, 'learning_rate': 3.746594005449591e-05, 'epoch': 0.75}\n",
      "{'loss': 0.3336, 'grad_norm': 9.15574836730957, 'learning_rate': 3.7375113533151685e-05, 'epoch': 0.76}\n",
      "{'loss': 0.3993, 'grad_norm': 10.398420333862305, 'learning_rate': 3.728428701180745e-05, 'epoch': 0.76}\n",
      "{'loss': 0.4109, 'grad_norm': 0.8092342019081116, 'learning_rate': 3.719346049046322e-05, 'epoch': 0.77}\n",
      "{'loss': 0.5825, 'grad_norm': 8.402654647827148, 'learning_rate': 3.710263396911898e-05, 'epoch': 0.77}\n",
      "{'loss': 0.4914, 'grad_norm': 11.088566780090332, 'learning_rate': 3.7011807447774755e-05, 'epoch': 0.78}\n",
      "{'loss': 0.3492, 'grad_norm': 15.672110557556152, 'learning_rate': 3.692098092643052e-05, 'epoch': 0.78}\n",
      "{'loss': 0.4007, 'grad_norm': 4.065282821655273, 'learning_rate': 3.683015440508629e-05, 'epoch': 0.79}\n",
      "{'loss': 0.5408, 'grad_norm': 28.71380615234375, 'learning_rate': 3.673932788374205e-05, 'epoch': 0.8}\n",
      "{'loss': 0.4875, 'grad_norm': 14.848721504211426, 'learning_rate': 3.6648501362397825e-05, 'epoch': 0.8}\n",
      "{'loss': 0.4248, 'grad_norm': 9.98867416381836, 'learning_rate': 3.655767484105359e-05, 'epoch': 0.81}\n",
      "{'loss': 0.6778, 'grad_norm': 3.870351791381836, 'learning_rate': 3.646684831970936e-05, 'epoch': 0.81}\n",
      "{'loss': 0.5858, 'grad_norm': 10.850048065185547, 'learning_rate': 3.637602179836512e-05, 'epoch': 0.82}\n",
      "{'loss': 0.3505, 'grad_norm': 3.5080058574676514, 'learning_rate': 3.628519527702089e-05, 'epoch': 0.82}\n",
      "{'loss': 0.5063, 'grad_norm': 25.493301391601562, 'learning_rate': 3.619436875567666e-05, 'epoch': 0.83}\n",
      "{'loss': 0.5633, 'grad_norm': 21.028953552246094, 'learning_rate': 3.610354223433243e-05, 'epoch': 0.83}\n",
      "{'loss': 0.5322, 'grad_norm': 11.555377006530762, 'learning_rate': 3.601271571298819e-05, 'epoch': 0.84}\n",
      "{'loss': 0.3582, 'grad_norm': 8.743794441223145, 'learning_rate': 3.592188919164396e-05, 'epoch': 0.84}\n",
      "{'loss': 0.4905, 'grad_norm': 31.468908309936523, 'learning_rate': 3.583106267029973e-05, 'epoch': 0.85}\n",
      "{'loss': 0.3586, 'grad_norm': 9.1573486328125, 'learning_rate': 3.57402361489555e-05, 'epoch': 0.86}\n",
      "{'loss': 0.4806, 'grad_norm': 1.2532384395599365, 'learning_rate': 3.564940962761126e-05, 'epoch': 0.86}\n",
      "{'loss': 0.4845, 'grad_norm': 9.148209571838379, 'learning_rate': 3.555858310626703e-05, 'epoch': 0.87}\n",
      "{'loss': 0.5708, 'grad_norm': 16.072227478027344, 'learning_rate': 3.54677565849228e-05, 'epoch': 0.87}\n",
      "{'loss': 0.6168, 'grad_norm': 16.61713218688965, 'learning_rate': 3.537693006357857e-05, 'epoch': 0.88}\n",
      "{'loss': 0.4731, 'grad_norm': 18.251811981201172, 'learning_rate': 3.528610354223433e-05, 'epoch': 0.88}\n",
      "{'loss': 0.2875, 'grad_norm': 1.7871109247207642, 'learning_rate': 3.51952770208901e-05, 'epoch': 0.89}\n",
      "{'loss': 0.4819, 'grad_norm': 0.7893496155738831, 'learning_rate': 3.510445049954587e-05, 'epoch': 0.89}\n",
      "{'loss': 0.5325, 'grad_norm': 12.632226943969727, 'learning_rate': 3.501362397820164e-05, 'epoch': 0.9}\n",
      "{'loss': 0.3726, 'grad_norm': 1.6363433599472046, 'learning_rate': 3.49227974568574e-05, 'epoch': 0.9}\n",
      "{'loss': 0.4769, 'grad_norm': 4.49299430847168, 'learning_rate': 3.483197093551317e-05, 'epoch': 0.91}\n",
      "{'loss': 0.3846, 'grad_norm': 8.558882713317871, 'learning_rate': 3.474114441416894e-05, 'epoch': 0.92}\n",
      "{'loss': 0.5251, 'grad_norm': 21.11967658996582, 'learning_rate': 3.465031789282471e-05, 'epoch': 0.92}\n",
      "{'loss': 0.4236, 'grad_norm': 2.563279628753662, 'learning_rate': 3.455949137148047e-05, 'epoch': 0.93}\n",
      "{'loss': 0.4, 'grad_norm': 24.070402145385742, 'learning_rate': 3.446866485013624e-05, 'epoch': 0.93}\n",
      "{'loss': 0.3602, 'grad_norm': 11.286330223083496, 'learning_rate': 3.437783832879201e-05, 'epoch': 0.94}\n",
      "{'loss': 0.4655, 'grad_norm': 15.662797927856445, 'learning_rate': 3.428701180744778e-05, 'epoch': 0.94}\n",
      "{'loss': 0.7003, 'grad_norm': 7.584454536437988, 'learning_rate': 3.419618528610354e-05, 'epoch': 0.95}\n",
      "{'loss': 0.3996, 'grad_norm': 18.699525833129883, 'learning_rate': 3.410535876475931e-05, 'epoch': 0.95}\n",
      "{'loss': 0.5415, 'grad_norm': 19.421348571777344, 'learning_rate': 3.401453224341508e-05, 'epoch': 0.96}\n",
      "{'loss': 0.5266, 'grad_norm': 23.938732147216797, 'learning_rate': 3.392370572207085e-05, 'epoch': 0.96}\n",
      "{'loss': 0.4415, 'grad_norm': 5.888362407684326, 'learning_rate': 3.383287920072662e-05, 'epoch': 0.97}\n",
      "{'loss': 0.4195, 'grad_norm': 8.62922477722168, 'learning_rate': 3.374205267938238e-05, 'epoch': 0.98}\n",
      "{'loss': 0.4642, 'grad_norm': 3.830699920654297, 'learning_rate': 3.3651226158038145e-05, 'epoch': 0.98}\n",
      "{'loss': 0.378, 'grad_norm': 0.9156711101531982, 'learning_rate': 3.356039963669392e-05, 'epoch': 0.99}\n",
      "{'loss': 0.4839, 'grad_norm': 5.159903526306152, 'learning_rate': 3.346957311534969e-05, 'epoch': 0.99}\n",
      "{'loss': 0.3712, 'grad_norm': 7.148130893707275, 'learning_rate': 3.337874659400545e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "924e10b4ca2e430fb67124832236624e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/230 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4671715795993805, 'eval_runtime': 100.0594, 'eval_samples_per_second': 36.678, 'eval_steps_per_second': 2.299, 'epoch': 1.0}\n",
      "{'loss': 0.4183, 'grad_norm': 10.312958717346191, 'learning_rate': 3.3287920072661215e-05, 'epoch': 1.0}\n",
      "{'loss': 0.3641, 'grad_norm': 4.581229209899902, 'learning_rate': 3.319709355131699e-05, 'epoch': 1.01}\n",
      "{'loss': 0.252, 'grad_norm': 2.162550449371338, 'learning_rate': 3.310626702997276e-05, 'epoch': 1.01}\n",
      "{'loss': 0.4211, 'grad_norm': 17.339492797851562, 'learning_rate': 3.301544050862852e-05, 'epoch': 1.02}\n",
      "{'loss': 0.187, 'grad_norm': 15.62761402130127, 'learning_rate': 3.2924613987284285e-05, 'epoch': 1.02}\n",
      "{'loss': 0.2787, 'grad_norm': 11.497817993164062, 'learning_rate': 3.283378746594006e-05, 'epoch': 1.03}\n",
      "{'loss': 0.278, 'grad_norm': 10.624368667602539, 'learning_rate': 3.274296094459583e-05, 'epoch': 1.04}\n",
      "{'loss': 0.3473, 'grad_norm': 23.724443435668945, 'learning_rate': 3.265213442325159e-05, 'epoch': 1.04}\n",
      "{'loss': 0.1907, 'grad_norm': 2.3818275928497314, 'learning_rate': 3.2561307901907355e-05, 'epoch': 1.05}\n",
      "{'loss': 0.2995, 'grad_norm': 14.846009254455566, 'learning_rate': 3.247048138056313e-05, 'epoch': 1.05}\n",
      "{'loss': 0.2837, 'grad_norm': 2.238058090209961, 'learning_rate': 3.23796548592189e-05, 'epoch': 1.06}\n",
      "{'loss': 0.2205, 'grad_norm': 0.06638313829898834, 'learning_rate': 3.228882833787466e-05, 'epoch': 1.06}\n",
      "{'loss': 0.6017, 'grad_norm': 7.308829307556152, 'learning_rate': 3.2198001816530425e-05, 'epoch': 1.07}\n",
      "{'loss': 0.3192, 'grad_norm': 29.590185165405273, 'learning_rate': 3.21071752951862e-05, 'epoch': 1.07}\n",
      "{'loss': 0.2298, 'grad_norm': 3.6075265407562256, 'learning_rate': 3.201634877384197e-05, 'epoch': 1.08}\n",
      "{'loss': 0.3189, 'grad_norm': 13.579530715942383, 'learning_rate': 3.192552225249773e-05, 'epoch': 1.08}\n",
      "{'loss': 0.1761, 'grad_norm': 1.8726269006729126, 'learning_rate': 3.1834695731153495e-05, 'epoch': 1.09}\n",
      "{'loss': 0.3257, 'grad_norm': 4.75633430480957, 'learning_rate': 3.174386920980927e-05, 'epoch': 1.1}\n",
      "{'loss': 0.3411, 'grad_norm': 0.8674479722976685, 'learning_rate': 3.165304268846504e-05, 'epoch': 1.1}\n",
      "{'loss': 0.389, 'grad_norm': 4.595182418823242, 'learning_rate': 3.15622161671208e-05, 'epoch': 1.11}\n",
      "{'loss': 0.3283, 'grad_norm': 15.173709869384766, 'learning_rate': 3.1471389645776565e-05, 'epoch': 1.11}\n",
      "{'loss': 0.3785, 'grad_norm': 6.375140190124512, 'learning_rate': 3.138056312443234e-05, 'epoch': 1.12}\n",
      "{'loss': 0.3893, 'grad_norm': 6.972586154937744, 'learning_rate': 3.128973660308811e-05, 'epoch': 1.12}\n",
      "{'loss': 0.3082, 'grad_norm': 8.116924285888672, 'learning_rate': 3.119891008174387e-05, 'epoch': 1.13}\n",
      "{'loss': 0.1819, 'grad_norm': 22.149822235107422, 'learning_rate': 3.1108083560399635e-05, 'epoch': 1.13}\n",
      "{'loss': 0.3139, 'grad_norm': 11.65363597869873, 'learning_rate': 3.10172570390554e-05, 'epoch': 1.14}\n",
      "{'loss': 0.3564, 'grad_norm': 14.965353965759277, 'learning_rate': 3.092643051771118e-05, 'epoch': 1.14}\n",
      "{'loss': 0.1883, 'grad_norm': 0.34469670057296753, 'learning_rate': 3.083560399636694e-05, 'epoch': 1.15}\n",
      "{'loss': 0.176, 'grad_norm': 4.448007106781006, 'learning_rate': 3.0744777475022705e-05, 'epoch': 1.16}\n",
      "{'loss': 0.1232, 'grad_norm': 0.2865724563598633, 'learning_rate': 3.065395095367847e-05, 'epoch': 1.16}\n",
      "{'loss': 0.2794, 'grad_norm': 15.077754974365234, 'learning_rate': 3.056312443233425e-05, 'epoch': 1.17}\n",
      "{'loss': 0.303, 'grad_norm': 16.975669860839844, 'learning_rate': 3.047229791099001e-05, 'epoch': 1.17}\n",
      "{'loss': 0.4373, 'grad_norm': 34.651153564453125, 'learning_rate': 3.038147138964578e-05, 'epoch': 1.18}\n",
      "{'loss': 0.4563, 'grad_norm': 30.24018096923828, 'learning_rate': 3.0290644868301543e-05, 'epoch': 1.18}\n",
      "{'loss': 0.392, 'grad_norm': 9.04100513458252, 'learning_rate': 3.0199818346957314e-05, 'epoch': 1.19}\n",
      "{'loss': 0.3655, 'grad_norm': 4.406312942504883, 'learning_rate': 3.010899182561308e-05, 'epoch': 1.19}\n",
      "{'loss': 0.6158, 'grad_norm': 7.797181129455566, 'learning_rate': 3.001816530426885e-05, 'epoch': 1.2}\n",
      "{'loss': 0.3056, 'grad_norm': 16.698450088500977, 'learning_rate': 2.9927338782924613e-05, 'epoch': 1.2}\n",
      "{'loss': 0.2779, 'grad_norm': 1.0870020389556885, 'learning_rate': 2.9836512261580384e-05, 'epoch': 1.21}\n",
      "{'loss': 0.3114, 'grad_norm': 7.389204502105713, 'learning_rate': 2.974568574023615e-05, 'epoch': 1.22}\n",
      "{'loss': 0.4625, 'grad_norm': 38.68992614746094, 'learning_rate': 2.965485921889192e-05, 'epoch': 1.22}\n",
      "{'loss': 0.1637, 'grad_norm': 1.2312276363372803, 'learning_rate': 2.9564032697547683e-05, 'epoch': 1.23}\n",
      "{'loss': 0.4795, 'grad_norm': 17.71413803100586, 'learning_rate': 2.9473206176203454e-05, 'epoch': 1.23}\n",
      "{'loss': 0.3392, 'grad_norm': 0.5696954131126404, 'learning_rate': 2.938237965485922e-05, 'epoch': 1.24}\n",
      "{'loss': 0.2931, 'grad_norm': 1.084521770477295, 'learning_rate': 2.929155313351499e-05, 'epoch': 1.24}\n",
      "{'loss': 0.3957, 'grad_norm': 2.9909985065460205, 'learning_rate': 2.9200726612170753e-05, 'epoch': 1.25}\n",
      "{'loss': 0.2793, 'grad_norm': 1.0631002187728882, 'learning_rate': 2.9109900090826524e-05, 'epoch': 1.25}\n",
      "{'loss': 0.2315, 'grad_norm': 7.8903326988220215, 'learning_rate': 2.901907356948229e-05, 'epoch': 1.26}\n",
      "{'loss': 0.4673, 'grad_norm': 28.040552139282227, 'learning_rate': 2.892824704813806e-05, 'epoch': 1.26}\n",
      "{'loss': 0.4305, 'grad_norm': 18.15622901916504, 'learning_rate': 2.8837420526793823e-05, 'epoch': 1.27}\n",
      "{'loss': 0.5133, 'grad_norm': 5.831995010375977, 'learning_rate': 2.8746594005449594e-05, 'epoch': 1.28}\n",
      "{'loss': 0.2516, 'grad_norm': 13.726819038391113, 'learning_rate': 2.865576748410536e-05, 'epoch': 1.28}\n",
      "{'loss': 0.3012, 'grad_norm': 0.40174785256385803, 'learning_rate': 2.856494096276113e-05, 'epoch': 1.29}\n",
      "{'loss': 0.2375, 'grad_norm': 2.324528932571411, 'learning_rate': 2.8474114441416893e-05, 'epoch': 1.29}\n",
      "{'loss': 0.2872, 'grad_norm': 7.716228008270264, 'learning_rate': 2.8383287920072667e-05, 'epoch': 1.3}\n",
      "{'loss': 0.4098, 'grad_norm': 5.978085041046143, 'learning_rate': 2.829246139872843e-05, 'epoch': 1.3}\n",
      "{'loss': 0.3175, 'grad_norm': 10.53731632232666, 'learning_rate': 2.82016348773842e-05, 'epoch': 1.31}\n",
      "{'loss': 0.3949, 'grad_norm': 12.769346237182617, 'learning_rate': 2.8110808356039963e-05, 'epoch': 1.31}\n",
      "{'loss': 0.3709, 'grad_norm': 11.190168380737305, 'learning_rate': 2.801998183469573e-05, 'epoch': 1.32}\n",
      "{'loss': 0.2466, 'grad_norm': 10.536224365234375, 'learning_rate': 2.79291553133515e-05, 'epoch': 1.32}\n",
      "{'loss': 0.4082, 'grad_norm': 6.623011112213135, 'learning_rate': 2.783832879200727e-05, 'epoch': 1.33}\n",
      "{'loss': 0.1813, 'grad_norm': 9.16486644744873, 'learning_rate': 2.7747502270663033e-05, 'epoch': 1.34}\n",
      "{'loss': 0.398, 'grad_norm': 10.156213760375977, 'learning_rate': 2.76566757493188e-05, 'epoch': 1.34}\n",
      "{'loss': 0.2204, 'grad_norm': 25.61407470703125, 'learning_rate': 2.756584922797457e-05, 'epoch': 1.35}\n",
      "{'loss': 0.5028, 'grad_norm': 30.38574981689453, 'learning_rate': 2.747502270663034e-05, 'epoch': 1.35}\n",
      "{'loss': 0.3965, 'grad_norm': 20.01950454711914, 'learning_rate': 2.7384196185286103e-05, 'epoch': 1.36}\n",
      "{'loss': 0.3094, 'grad_norm': 2.0214078426361084, 'learning_rate': 2.729336966394187e-05, 'epoch': 1.36}\n",
      "{'loss': 0.4341, 'grad_norm': 2.6553032398223877, 'learning_rate': 2.720254314259764e-05, 'epoch': 1.37}\n",
      "{'loss': 0.2357, 'grad_norm': 0.2894267737865448, 'learning_rate': 2.711171662125341e-05, 'epoch': 1.37}\n",
      "{'loss': 0.2876, 'grad_norm': 14.503589630126953, 'learning_rate': 2.7020890099909173e-05, 'epoch': 1.38}\n",
      "{'loss': 0.4368, 'grad_norm': 38.1639404296875, 'learning_rate': 2.693006357856494e-05, 'epoch': 1.38}\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Shared memory manager connection has timed out",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 63\u001b[0m\n\u001b[1;32m     55\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     56\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,                         \u001b[38;5;66;03m# the model to be trained\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,                  \u001b[38;5;66;03m# training arguments\u001b[39;00m\n\u001b[1;32m     58\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtrain_dataset,         \u001b[38;5;66;03m# training dataset\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39mval_dataset,            \u001b[38;5;66;03m# evaluation dataset\u001b[39;00m\n\u001b[1;32m     60\u001b[0m )\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the validation set\u001b[39;00m\n\u001b[1;32m     66\u001b[0m trainer\u001b[38;5;241m.\u001b[39mevaluate()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/sentiment-analysis/lib/python3.9/site-packages/transformers/trainer.py:2052\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2050\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2051\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2052\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2054\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2056\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2057\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/sentiment-analysis/lib/python3.9/site-packages/transformers/trainer.py:2345\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2342\u001b[0m     rng_to_sync \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2344\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 2345\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(epoch_iterator):\n\u001b[1;32m   2346\u001b[0m     total_batched_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2348\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39minclude_num_input_tokens_seen:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/sentiment-analysis/lib/python3.9/site-packages/accelerate/data_loader.py:561\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     current_batch \u001b[38;5;241m=\u001b[39m send_to_device(current_batch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_non_blocking)\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_state_dict()\n\u001b[0;32m--> 561\u001b[0m next_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_batches:\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m current_batch\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/sentiment-analysis/lib/python3.9/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/sentiment-analysis/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1448\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1448\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1449\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1451\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/sentiment-analysis/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1412\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1408\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1409\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1410\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1411\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1412\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1413\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1414\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/sentiment-analysis/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1243\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1231\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1232\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1241\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1242\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1243\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1244\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1245\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1246\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1247\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1248\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/sentiment-analysis/lib/python3.9/multiprocessing/queues.py:122\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rlock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# unserialize the data after having released the lock\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ForkingPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/sentiment-analysis/lib/python3.9/site-packages/torch/multiprocessing/reductions.py:560\u001b[0m, in \u001b[0;36mrebuild_storage_filename\u001b[0;34m(cls, manager, handle, size, dtype)\u001b[0m\n\u001b[1;32m    558\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m storage\u001b[38;5;241m.\u001b[39m_shared_decref()\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 560\u001b[0m     storage \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUntypedStorage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_shared_filename_cpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    562\u001b[0m     byte_size \u001b[38;5;241m=\u001b[39m size \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Shared memory manager connection has timed out"
     ]
    }
   ],
   "source": [
    "# Check if MPS (Apple's GPU) is available\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load your preprocessed dataset\n",
    "df = pd.read_csv('train_data.csv')\n",
    "\n",
    "# Ensure the 'Comment' column is in string format and drop any rows with NaN values\n",
    "df['Comment'] = df['Comment'].astype(str).fillna('')\n",
    "\n",
    "# Select the required columns\n",
    "df = df[['Comment', 'Sentiment']]\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(df['Comment'].tolist(), df['Sentiment'].tolist(), test_size=0.2)\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize the texts for both training and validation sets\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=128)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=128)\n",
    "\n",
    "# Convert the data into Hugging Face Dataset format\n",
    "train_dataset = Dataset.from_dict({\n",
    "    'input_ids': train_encodings['input_ids'],\n",
    "    'attention_mask': train_encodings['attention_mask'],\n",
    "    'labels': train_labels\n",
    "})\n",
    "\n",
    "val_dataset = Dataset.from_dict({\n",
    "    'input_ids': val_encodings['input_ids'],\n",
    "    'attention_mask': val_encodings['attention_mask'],\n",
    "    'labels': val_labels\n",
    "})\n",
    "\n",
    "# Load the pre-trained BERT model for sequence classification\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n",
    "model.to(device)  # Move model to MPS if available\n",
    "\n",
    "# Set up the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    eval_strategy=\"epoch\",     # evaluation strategy\n",
    "    per_device_train_batch_size=8,   # batch size for training\n",
    "    per_device_eval_batch_size=16,   # batch size for evaluation\n",
    "    num_train_epochs=3,              # number of training epochs\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=10,\n",
    "    dataloader_num_workers=4,        # Enable multi-threading for data loading\n",
    ")\n",
    "\n",
    "# Define the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the model to be trained\n",
    "    args=training_args,                  # training arguments\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=val_dataset,            # evaluation dataset\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the validation dataset\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m eval_results \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241m.\u001b[39mevaluate()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Print the evaluation results\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluation results: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00meval_results\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation dataset\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "# Print the evaluation results\n",
    "print(f\"Evaluation results: {eval_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Get predictions for the validation dataset\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m predictions, labels, metrics \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(val_dataset)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Print the predicted labels and metrics\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredictions: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredictions\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "# Get predictions for the validation dataset\n",
    "predictions, labels, metrics = trainer.predict(val_dataset)\n",
    "\n",
    "# Print the predicted labels and metrics\n",
    "print(f\"Predictions: {predictions.argmax(-1)}\")\n",
    "print(f\"Metrics: {metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8483606557377049\n",
      "Precision: 0.846326746846525\n",
      "Recall: 0.8483606557377049\n",
      "F1-Score: 0.8471487726138608\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Convert predictions and labels to lists\n",
    "pred_labels = predictions.argmax(-1)\n",
    "true_labels = labels\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(true_labels, pred_labels)\n",
    "\n",
    "# Calculate precision, recall, and F1-score\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(true_labels, pred_labels, average='weighted')\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Test with a sample input\u001b[39;00m\n\u001b[1;32m     23\u001b[0m sample_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI am not liking this airline, it\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms service is slow & representatives aren\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt responsible\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 24\u001b[0m sentiment \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_sentiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted Sentiment: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msentiment\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m, in \u001b[0;36mpredict_sentiment\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_sentiment\u001b[39m(text):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Move the inputs to the MPS device\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m(text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Move model to the correct device\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     model\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "def predict_sentiment(text):\n",
    "    # Move the inputs to the MPS device\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(device)\n",
    "\n",
    "    # Move model to the correct device\n",
    "    model.to(device)\n",
    "    \n",
    "    # Use torch.no_grad() to disable gradient tracking\n",
    "    with torch.no_grad():\n",
    "        # Ensure outputs are also computed on the MPS device\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Move outputs back to CPU for processing and get the predicted sentiment\n",
    "    prediction = torch.argmax(outputs.logits.cpu(), dim=-1).item()\n",
    "\n",
    "    # Define the sentiment mapping\n",
    "    sentiments = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
    "\n",
    "    # Return the predicted sentiment\n",
    "    return sentiments[prediction]\n",
    "\n",
    "# Test with a sample input\n",
    "sample_text = \"I am not liking this airline, it's service is slow & representatives aren't responsible\"\n",
    "sentiment = predict_sentiment(sample_text)\n",
    "print(f\"Predicted Sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Save the model and tokenizer\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39msave_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./saved_model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39msave_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./saved_model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Save the model and tokenizer\n",
    "model.save_pretrained('./saved_model')\n",
    "tokenizer.save_pretrained('./saved_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model = BertForSequenceClassification.from_pretrained('./saved_model')\n",
    "tokenizer = BertTokenizer.from_pretrained('./saved_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x10f5b2ca0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')': /simple/numpy/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x10f5b2fa0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')': /simple/numpy/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x10f5de460>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')': /simple/numpy/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x10f5de610>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')': /simple/numpy/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x10f5de7c0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')': /simple/numpy/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement numpy==1.26.4 (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for numpy==1.26.4\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy==1.26.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
